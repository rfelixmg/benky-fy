{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a60ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast, itertools\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core structures\n",
    "with open('/Users/rafaelfelix/Projects/demos/benky-fy/tmp/core.json', 'r', encoding='utf-8') as f:\n",
    "    core_data = {key: pd.DataFrame(item) for key, item in json.load(f).items()}\n",
    "    structures = core_data['structures']\n",
    "    vocab = core_data['vocab'] = pd.read_json('/Users/rafaelfelix/Projects/demos/benky-fy/tmp/vocab.json')\n",
    "    verbs = pd.read_json('/Users/rafaelfelix/Projects/demos/benky-fy/tmp/verbs.json')\n",
    "vocab_interests = json.load(open('/Users/rafaelfelix/Projects/demos/benky-fy/tmp/vocab_interests.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f043b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59337295",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = structures.sample(1).iloc[0]\n",
    "# vocab intrests:\n",
    "#  politeness, people_identity, daily_life_lifestyle, places_travel_events, \n",
    "#  knowledge_communication, nature_description, actions_time, ai_professional\n",
    "vocab_criterias = [\n",
    "    (\"priority_group\", [\"p0\", \"p1\", \"p2\"]),\n",
    "    (\"tags\", vocab_interests['places_travel_events'])\n",
    "]\n",
    "\n",
    "tvocab = vocab.copy()\n",
    "for key, value in vocab_criterias:\n",
    "    tvocab = tvocab[tvocab[key].apply(lambda x: bool(set(x) & set(value)) if isinstance(x, list) else x in value)]\n",
    "\n",
    "words = {}\n",
    "for key, value in structure.slots.items():\n",
    "    if key == 'clause':\n",
    "        print(NotImplementedError(\"Clause is not implemented yet\"))\n",
    "    elif key == \"Verb\":\n",
    "        if value != \"any\" and value != [\"any\"]:\n",
    "            pool = verbs[verbs.tags.apply(\n",
    "                lambda x: bool(set(x['semantic'] if isinstance(x['semantic'], list) else [x['semantic']]) & set(value))\n",
    "            )]\n",
    "        else:\n",
    "            pool = verbs\n",
    "    elif key == \"Adj\":\n",
    "        pool = vocab[vocab.category.isin([\"adjective\"])]\n",
    "    else:\n",
    "        pool = tvocab[tvocab.category.isin(value)]\n",
    "    words[key] = pool.sample().iloc[0].english\n",
    "    \n",
    "print(\"structure: \", structure.structure)\n",
    "print(\"theme: \", random.choice(structure.theme))\n",
    "for key, value in words.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef9720",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs.tags.apply(lambda x: x['usage']).explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures.slots.apply(lambda x: x.keys()).explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f98201",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = vocab.english.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "context += verbs.english.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rafaelfelix/Projects/demos/benky-fy/tmp/context-words.txt', 'w') as f:\n",
    "    f.write('\\n'.join(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4638a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "483748b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Japanese Sentence Generator Ready!\n",
      "==================================================\n",
      "A ã¯ Adj ã§ã™\n",
      "A: donut\n",
      "Adj: [i-adj]\n"
     ]
    }
   ],
   "source": [
    "# Import the sentence generator\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "sys.path.append('../tmp')\n",
    "from main import JapaneseSentenceGenerator, Sentence\n",
    "\n",
    "# Initialize the generator\n",
    "generator = JapaneseSentenceGenerator()\n",
    "\n",
    "print(\"ğŸŒ Japanese Sentence Generator Ready!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Function to display sentences nicely\n",
    "def display_sentence(sentence: Sentence):\n",
    "    \"\"\"Display a sentence with nice formatting\"\"\"\n",
    "    print(f\"ğŸ¯ Theme: {sentence.theme}\")\n",
    "    print(f\"ğŸ“ Structure: {sentence.structure}\")\n",
    "    print(f\"ğŸ‡¯ğŸ‡µ Japanese: {sentence.japanese}\")\n",
    "    print(f\"ğŸ‡ºğŸ‡¸ English: {sentence.english}\")\n",
    "    print(f\"ğŸ”§ Components: {sentence.components}\")\n",
    "    print(f\"ğŸ“Œ Particles: {sentence.particles}\")\n",
    "    print(f\"â• Extensions: {sentence.extensions}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Test with different themes\n",
    "themes_to_test = [\"identity\", \"motion\", \"action_with_object\", \"description\", \"possession\"]\n",
    "\n",
    "sentence = generator.generate_sentence(random.choice(themes_to_test))\n",
    "print(sentence.structure)\n",
    "for key, value in sentence.components.items():\n",
    "    print(f\"{key}: {value['english']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4194d78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a possession sentence: ã“ã†ã¡ã‚ƒ ã® ã¦ã‚“ã·ã‚‰'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132374f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: i (formal)\n",
      "Verb: to forget\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852736cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0351e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced sentence generation with full metadata\n",
    "def display_enhanced_sentence(sentence: Sentence):\n",
    "    \"\"\"Display a sentence with full component metadata\"\"\"\n",
    "    print(f\"ğŸ¯ Theme: {sentence.theme}\")\n",
    "    print(f\"ğŸ“ Structure: {sentence.structure}\")\n",
    "    print(f\"ğŸ‡¯ğŸ‡µ Japanese: {sentence.japanese}\")\n",
    "    print(f\"ğŸ‡ºğŸ‡¸ English: {sentence.english}\")\n",
    "    print(f\"ğŸ“Œ Particles: {sentence.particles}\")\n",
    "    print(f\"â• Extensions: {sentence.extensions}\")\n",
    "    print(\"\\nğŸ”§ Component Details:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for slot_name, component in sentence.components.items():\n",
    "        print(f\"\\nğŸ“ {slot_name}:\")\n",
    "        if isinstance(component, dict):\n",
    "            # Display all available fields\n",
    "            for key, value in component.items():\n",
    "                if key == \"tags\" and isinstance(value, dict):\n",
    "                    print(f\"  ğŸ·ï¸  {key}:\")\n",
    "                    for tag_key, tag_value in value.items():\n",
    "                        print(f\"    - {tag_key}: {tag_value}\")\n",
    "                elif key == \"conjugations\" and isinstance(value, dict):\n",
    "                    print(f\"  ğŸ”„ {key}:\")\n",
    "                    for conj_key, conj_value in value.items():\n",
    "                        if isinstance(conj_value, dict):\n",
    "                            print(f\"    - {conj_key}: {conj_value.get('hiragana', conj_value)}\")\n",
    "                        else:\n",
    "                            print(f\"    - {conj_key}: {conj_value}\")\n",
    "                else:\n",
    "                    print(f\"  ğŸ“‹ {key}: {value}\")\n",
    "        else:\n",
    "            print(f\"  ğŸ“‹ Value: {component}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "# Generate and display an enhanced sentence\n",
    "print(\"ğŸš€ Enhanced Sentence Generation with Full Metadata:\")\n",
    "print(\"=\" * 60)\n",
    "enhanced_sentence = generator.generate_sentence(\"motion\")\n",
    "display_enhanced_sentence(enhanced_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475dadf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different themes with full metadata\n",
    "def compare_themes_with_metadata(themes_list):\n",
    "    \"\"\"Compare multiple themes showing full metadata\"\"\"\n",
    "    print(\"ğŸ” Theme Comparison with Full Metadata:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, theme in enumerate(themes_list, 1):\n",
    "        print(f\"\\nğŸ¯ THEME {i}: {theme.upper()}\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        sentence = generator.generate_sentence(theme)\n",
    "        \n",
    "        # Show basic info\n",
    "        print(f\"ğŸ“ Structure: {sentence.structure}\")\n",
    "        print(f\"ğŸ‡¯ğŸ‡µ Japanese: {sentence.japanese}\")\n",
    "        \n",
    "        # Show component metadata summary\n",
    "        print(f\"\\nğŸ”§ Components Summary:\")\n",
    "        for slot_name, component in sentence.components.items():\n",
    "            if isinstance(component, dict):\n",
    "                english = component.get(\"english\", \"N/A\")\n",
    "                japanese = component.get(\"kana\", component.get(\"hiragana\", component.get(\"kanji\", \"N/A\")))\n",
    "                tags = component.get(\"tags\", {})\n",
    "                print(f\"  ğŸ“ {slot_name}: {english} ({japanese})\")\n",
    "                if tags:\n",
    "                    semantic_tags = tags.get(\"semantic\", [])\n",
    "                    usage_tags = tags.get(\"usage\", [])\n",
    "                    if semantic_tags:\n",
    "                        print(f\"    ğŸ¯ Semantic: {semantic_tags}\")\n",
    "                    if usage_tags:\n",
    "                        print(f\"    ğŸ“š Usage: {usage_tags}\")\n",
    "            else:\n",
    "                print(f\"  ğŸ“ {slot_name}: {component}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Compare different themes\n",
    "themes_to_compare = [\"identity\", \"action_with_object\", \"description\", \"possession\"]\n",
    "compare_themes_with_metadata(themes_to_compare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7adcc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
